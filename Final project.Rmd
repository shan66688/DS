---
title: "P8106 Data Science II Final Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(magrittr)
library(knitr)
library(readr)
library(tidyverse)
library(haven)
library(readxl)
library(caret)
library(ISLR)
library(pls)
library(pROC)
library(class)
library(rpart)
library(party)
library(partykit)
library(tree)
library(randomForest)
library(gbm)
library(pander)
library(e1071)
library(tidytext)
library(tools)
library(openintro)
library(janitor)
library(glmnet)
library(pls)
library(gam)
```

## R Markdown

#best group start here 

###1. data preparation.

####1. Read raw data
```{r}
# read in raw data
# drug_data = read.csv("../data/State_Drug_Utilization_Data_2015.csv")
# drug_name = read_xlsx("../data/anxiety drug names.xlsx")
# sunshine = read_xlsx("../data/sunshine duration by state.xlsx")
# acs2015 = read.csv("../data/acs2015_county_data.csv")
# happy_rank = c(28, 2, 9, 44, 10, 4, 18, 27, 12, 41, 1, 36, 35, 46, 14, 25, 49, 42, 22, 34, 30, 39, 7, 43, 45, 3, 20, 38, 21, 32, 16, 40, 23, 15, 47, 48, 31, 33, 26, 19, 6, 37, 11, 8, 29, 17, 24, 50, 13, 5)
# happy = data.frame(cbind(state.name, happy_rank)) %>%
#   mutate(State = state.name) %>%
#   select(-state.name)
# physician=read_xlsx("../data/physician.xlsx")
# save(drug_data,drug_name,sunshine,acs2015,happy,physician, file="raw_data.Rdata")
```

####2. Summarize acs2015 data by state, and save it as "acs_summary_by_state.Rdata".
```{r}
# #acs data summary by state
# acs2015_summary = acs2015 %>%
#   group_by(State) %>%
#   summarize(population = sum(TotalPop, na.rm = TRUE), 
#             men = sum(Men, na.rm = TRUE)/population,
#             women = sum(Women, na.rm = TRUE)/population,
#             hispanic = sum(0.01*Hispanic * TotalPop, na.rm = TRUE)/population,
#             white = sum(0.01*White * TotalPop, na.rm = TRUE)/population,
#             black = sum(0.01*Black * TotalPop, na.rm = TRUE)/population,
#             asian = sum(0.01*Asian * TotalPop, na.rm = TRUE)/population,
#             native = sum(0.01*Native * TotalPop, na.rm = TRUE)/population,
#             pacific = sum(0.01*Pacific * TotalPop, na.rm = TRUE)/population,
#             citizen = sum(Citizen, na.rm = TRUE)/population,
#             ave_income = sum(Income * TotalPop, na.rm = TRUE)/population,
#             income_per_cap = sum(as.numeric(IncomePerCap) * TotalPop, na.rm = TRUE)/population,
#             ave_Poverty = sum(Poverty * TotalPop, na.rm = TRUE)/population,
#             ave_ChildPoverty = sum(ChildPoverty * TotalPop, na.rm = TRUE)/population,
#             ave_Professional = sum(Professional * TotalPop, na.rm = TRUE)/population,
#             ave_Service = sum(Service * TotalPop, na.rm = TRUE)/population,
#             ave_Office = sum(Office * TotalPop, na.rm = TRUE)/population,
#             ave_Construction = sum(Construction * TotalPop, na.rm = TRUE)/population,
#             ave_Production = sum(Production * TotalPop, na.rm = TRUE)/population,
#             ave_Drive = sum(Drive * TotalPop, na.rm = TRUE)/population,
#             ave_Carpool = sum(Carpool * TotalPop, na.rm = TRUE)/population,
#             ave_Transit = sum(Transit * TotalPop, na.rm = TRUE)/population,
#             ave_Walk = sum(Walk * TotalPop, na.rm = TRUE)/population,
#             ave_WorkAtHome = sum(WorkAtHome * TotalPop, na.rm = TRUE)/population,
#             ave_MeanCommute = sum(MeanCommute * TotalPop, na.rm = TRUE)/population,
#             ave_SelfEmployed = sum(SelfEmployed * Employed, na.rm = TRUE)/sum(Employed),
#             ave_PublicWork = sum(PublicWork * Employed, na.rm = TRUE)/sum(Employed),
#             ave_PrivateWork = sum(PrivateWork * Employed, na.rm = TRUE)/sum(Employed),
#             ave_FamilyWork = sum(FamilyWork * Employed, na.rm = TRUE)/sum(Employed),
#             ave_Unemployment = sum(Unemployment * TotalPop, na.rm = TRUE)/population)
# 
# save(acs2015_summary, file = "acs_summary_by_state.Rdata")
```

####3. Prepare the drug_name data: get all the names ready for "join" and save it as "drug name.Rdata".
```{r}
# drug_name_1 = drug_name %>%
#   unnest_tokens(word, name) %>%
#   unique()
# 
# data("stop_words")
# drug_name_2 = anti_join(drug_name_1, stop_words) %>%
#   mutate(word_upper = toupper(word), word_first_upper = toTitleCase(word)) %>%
#   gather(type, Product.Name, 1:3) %>%
#   select(Product.Name)
# 
# save(drug_name_2, file = "drug name.Rdata")
```

####4. Select anti-anxiety drug by merging drug_data with "drug name.Rdata"(drug_name_2), and summarize by state. The result is "anxiety drug by state.Rdata".
```{r}
# drug_data_anxiety_state = merge(drug_name_2, drug_data) %>%
#   mutate(Units.Reimbursed = as.numeric(Units.Reimbursed),
#          Number.of.Prescriptions = as.numeric(Number.of.Prescriptions),
#          Total.Amount.Reimbursed = as.numeric(Total.Amount.Reimbursed),
#          Medicaid.Amount.Reimbursed = as.numeric(Medicaid.Amount.Reimbursed),
#          State = abbr2state(State)) %>%
#   filter(Number.of.Prescriptions > 1, !is.na(State)) %>%
#   mutate(Product.Name = toupper(Product.Name)) %>%
#   group_by(State, Product.Name) %>%
#   summarise(Rx.Number = sum((Number.of.Prescriptions), na.rm=TRUE),
#             Reimburse.Unit = sum((Units.Reimbursed), na.rm=TRUE),
#             Reimburse.Amount.Tot = sum((Total.Amount.Reimbursed), na.rm=TRUE),
#             Reimburse.Amount.Medicaid = sum((Medicaid.Amount.Reimbursed), na.rm=TRUE))
# 
# save(drug_data_anxiety_state, file = "anxiety drug by state.Rdata")
```

####5. Merge all data sets by state, and save as "data.Rdata", which is our final data set for now.
```{r}
# geo_center = data.frame(cbind(state.name, state.center$x, state.center$y))
# colnames(geo_center)<-(c("State", "longitude", "latitude"))
# 
# data = Reduce(function(x, y) merge(x, y, all=TRUE), list(acs2015_summary, drug_data_anxiety_state, happy, physician, sunshine, geo_center))
# 
# data_final = data %>%
#   group_by(State) %>%
#   mutate(sum_reimburse = sum(Reimburse.Amount.Tot), reimburse_per_cap = sum_reimburse/population) %>%
#   select(-Product.Name, -Rx.Number, -Reimburse.Unit, -Reimburse.Amount.Tot, -Reimburse.Amount.Medicaid) %>%
#   distinct() %>%
#   na.omit()
# 
# save(data_final, file = "data.Rdata")
```

Description of "data" variables:
"State": 50 states plus DC.
"population": Total population in the state.
"men" and "women": Proportion of men or women in the population. They add up to 1.
"hispanic", "white", "black", "asian", "native", and "pacific": Proportion of each race in the population. They add up to 1.
"citizen": Proportion of citizen.
"ave_income": Average annual income of each employee.
"income_per_cap": Average annual income per capita.
"ave_Poverty": average poverty
"ave_ChildPoverty": average child poverty
"ave_Professional", "ave_Service", "ave_Office", "ave_Construction", "ave_Production": Percetage of employee working in a specific career. They add up to 100.
"ave_Drive", "ave_Carpool", "ave_Transit", "ave_Walk": Percetage of people taking a specific commuting method. They add up to 100.
"ave_MeanCommute": I am not quite sure. Probably the commuting time in minutes?
"ave_SelfEmployed", "ave_PublicWork", "ave_PrivateWork", "ave_FamilyWork": Percetage of people with a specific employment status. They add up to 100.
"ave_Unemployment": Unemployment rate.
("Product.Name": Name of the drug)
("Rx number": number of prescriptions.)
("Reimburse.Unit": No idea...)
("Reimburse.Amount.Tot": Total amount of reimbursment for a drug.)
("Reimburse.Amount.Medicaid": Total amount of reimbursment by Medicaid for a drug.)
"happy_rank": The rank of happiness of the state among all 50 states.
"physician per 100,000 population": Licensed, active physician per 100,000 population.
"Place", "% Sun", "Total hours", "Clear days": These are for the sunshine data. "Place" is where the following three measurements were taken.
"Longitude" and "Latitude": The coordinates of the geometric center of each state.
"sum_reimburse": total number of reimburesement of anti_anxiety drugs.

We probably will use "Rx number", "Reimburse.Amount.Tot", or "Reimburse.Amount.Medicaid" as the reponse, and the other variables as the predictors.

###3. Unsupervised learning.

####1. heirachical clustering
```{r}
data_cluster = data_final %>%
  ungroup() %>%
  clean_names() %>%
  select(-state, -place, -percent_sun, -total_hours, -population, -sum_reimburse, -longitude, -latitude)

data_cluster <- data.frame(lapply(data_cluster, function(x) as.numeric(x)))

data_cluster = scale(data_cluster)

row.names(data_cluster) = state.name

hc.complete <- hclust(dist(data_cluster), method = "complete")
plot(hc.complete,main = "Complete Linkage", xlab = "", sub = "", cex = .9)
rect.hclust(hc.complete, h = 9.5)
```

####2. PCA analysis
```{r}
data_pca = data_final %>%
  ungroup() %>%
  clean_names() %>%
  select(-state, -place, -percent_sun, -total_hours, -population, -sum_reimburse)

data_pca <- data.frame(lapply(data_pca, function(x) as.numeric(as.character(x))))

pr.out <- prcomp(data_pca, scale = TRUE)
plot(pr.out$"x"[,1],pr.out$"x"[,2],xlab="PC1",ylab="PC2")
```

###4. Supervised learning.

1. Split data into train and test datasets.
```{r}
data_regression = data_final %>%
  ungroup() %>%
  clean_names() %>%
  select(-state, -place, -percent_sun, -total_hours, -population, -sum_reimburse)

data_regression <- data.frame(lapply(data_regression, function(x) as.numeric(as.character(x))))

row.names(data_cluster) = state.name

set.seed(2018)
train_row = sample(1:50, 30)
train = data_regression[train_row, ]
test = data_regression[-train_row, ]
```

2. Linear regression
```{r}
linear <- lm(reimburse_per_cap~., data = train)
summary(linear)
```

3. ridge regression

(1). Fit ridge regression models with different $\lambda$s.
```{r}
# matrix of predictors
x_ridge = model.matrix(reimburse_per_cap~.,train)[,-1]
# vector of response
y_ridge = train$reimburse_per_cap

# ridge regression
# set a grid for lambda
grid.ridge <- 10^seq(10,-5,length=100)
# fit the ridge regression (alpha = 0) with a sequence of lambdas
# glmnet() function standardizes the variables by default
ridge = glmnet(x_ridge,y_ridge,alpha=0,lambda = grid.ridge)

# coefficent matrix for different values of lambda in your grid
# each column is the fit corresponding to one lambda value
#coef(ridge)
#dim(coef(ridge))
```

(2). Cross-validation (10-fold) to identify the $\lambda$ that returned the lowest MSE.
```{r}
set.seed(2018)

# Cross-validation for ridge regression
cv.out_ridge = cv.glmnet(x_ridge,y_ridge,alpha=0, lambda = grid.ridge,
                   type.measure = "mse")

# two vertical lines for minimal MSE and 1SE rule
plot(cv.out_ridge)

# final coefficents
best.lambda_ridge <- cv.out_ridge$lambda.min
best_ridge_coef = predict(ridge, s=best.lambda_ridge, type="coefficients")
```

The chosen $\lambda$ is `r best.lambda_ridge`, and the corresponding ridge regression coefficients are
```{r}
best_ridge_coef
```

(3). Calculate test MSE with the test data.
```{r}
# predict the new obesrvations from test data
x_test_ridge = model.matrix(reimburse_per_cap~.,test)[,-1]
ridge_pred <- predict(ridge, s=best.lambda_ridge, newx = x_test_ridge)
# test set error
MSE_test_ridge = mean((ridge_pred - test$reimburse_per_cap)^2)
MSE_test_ridge
```

The test MSE is `r MSE_test_ridge`.

4. Lasso regression

(1) Fit lasso regression models with different $\lambda$s.
```{r}
# matrix of predictors
x_lasso = model.matrix(reimburse_per_cap~.,train)[,-1]
# vector of response
y_lasso = train$reimburse_per_cap

# lasso regression
# set a grid for lambda
grid.lasso <- exp(seq(10,-2,length=100))
# fit the lasso regression (alpha = 1) with a sequence of lambdas
# glmnet() function standardizes the variables by default
lasso = glmnet(x_lasso,y_lasso,alpha=1,lambda = grid.lasso)

# coefficent matrix for different values of lambda in your grid
# each column is the fit corresponding to one lambda value
#coef(lasso)
#dim(coef(lasso))
```

(2) Cross-validation (10-fold) to identify the $\lambda$ that returned the lowest MSE.
```{r}
# Cross-validation for ridge regression
cv.out_lasso = cv.glmnet(x_lasso,y_lasso,alpha=1, lambda = grid.lasso,
                   type.measure = "mse")

# two vertical lines for minimal MSE and 1SE rule
plot(cv.out_lasso)

# final coefficents
best.lambda_lasso <- cv.out_lasso$lambda.min
best_lasso_coef = predict(lasso, s=best.lambda_lasso, type="coefficients")
```

The chosen $\lambda$ is `r best.lambda_lasso`, and the corresponding lasso regression coefficients are
```{r}
best_lasso_coef
```

(3). Calculate test MSE with the test data.
```{r}
# predict the new obesrvations from test data
x_test_lasso = model.matrix(reimburse_per_cap~.,test)[,-1]
lasso_pred <- predict(lasso, s = best.lambda_lasso, newx = x_test_lasso)
# test set error
MSE_test_lasso = mean((lasso_pred - test$reimburse_per_cap)^2)
MSE_test_lasso
```

The test MSE is `r MSE_test_lasso`.

(4). Calculate the number or non-zero coefficients
```{r}
n_nonzero = sum(best_lasso_coef != 0 )
n_nonzero
```

So the number or non-zero coefficients is `r n_nonzero`.

4.1 gam with the nonzero predictors in lasso model:
```{r, warning=FALSE}
gam=gam(reimburse_per_cap~s(citizen,6)+s(ave_service,6)+s(ave_construction,6)+s(ave_transit,6)+s(ave_walk,6)+s(ave_public_work,6)+s(physician_per_100_000_population,6) ,data=train)

par(mfrow=c(2,4))
plot(gam,col="blue")

gam_pred <- predict(gam, newx = test)
MSE_test_gam = mean((gam_pred - test$reimburse_per_cap)^2)
MSE_test_gam
```


5. PLS regression

(1) Fit pls regression models with the different M's chosen by 10-fold cross-validation.
```{r}
pls = plsr(reimburse_per_cap~., 
               data=train, 
               scale=TRUE,  
               validation ="CV")
summary(pls)
```

(2) Find the M that returns the best fitting result.
```{r}
validationplot(pls,val.type = "MSEP")
ncomp = selectNcomp(pls, method = c("onesigma"))
ncomp
```
Thus, the value of M selected by cross-validation is `r ncomp`.

(3) Calculate test MSE with the test data.
```{r}
pls_pred = predict(pls,test,ncomp = ncomp)
MSE_test_pls = mean((pls_pred - test$reimburse_per_cap)^2)
MSE_test_pls
```
The test MSE is `r MSE_test_pls`.

6.PCR regression
```{r}
pcr_model <- pcr(reimburse_per_cap~., data = train, scale = TRUE, validation = "CV")
summary(pcr_model)

validationplot(pcr_model, val.type="MSEP")
#from the above plot, we choose ncomp to be 5.
pcr_pred = predict(pcr_model,test,ncomp = 5)
MSE_test_pcr = mean((pcr_pred - test$reimburse_per_cap)^2)
MSE_test_pcr
```
The test MSE is `r MSE_test_pcr`.


```{r}
MSE=matrix(c(MSE_test_ridge,MSE_test_lasso, MSE_test_gam, MSE_test_pls, MSE_test_pcr))
rownames(MSE) <- c("ridge","lasso","gam","pls", "pcr")
colnames(MSE) = "test MSE"
MSE
```
















